{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd37de8e",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\ML-project\\GEN-AI-H2S-notebooks-\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> f76dcb1c84655a30a61595dcf39bf2098e3425c6
   "source": [
    "import os\n",
    "import io\n",
    "from google.cloud import vision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b60b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "88c01696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\ML-project\\GEN-AI-H2S-notebooks-\\venv\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:2242: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trocr_doc = pipeline('image-to-text', model= \"microsoft/trocr-base-printed\", device= DEVICE)\n",
    "trocr_scene =pipeline(\"image-to-text\", model=\"microsoft/trocr-base-stage1\", device=DEVICE)\n",
    "\n",
    "print(\"\\n--- All models loaded successfully! ---\")\n",
    "def ETFI(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        generated_text_doc= trocr_doc(img)[0]['generated_text']\n",
    "        generated_text_scene= trocr_scene(img)[0]['generated_text']\n",
    "        print(f\"\\nDocument Model Output: '{generated_text_doc}'\")\n",
    "        print(f\"\\nscene Model Output: '{generated_text_scene}'\")\n",
    "        if len(generated_text_scene) > len(generated_text_doc):\n",
    "            return generated_text_scene\n",
    "        else:\n",
    "            return generated_text_doc\n",
    "    except Exception as e:\n",
    "        print(f'An Error occured: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d818005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Model Output: '(000)'\n",
      "\n",
      "scene Model Output: 'TOBACCO CORPORATIONAL ANALYTICAL PROTECTION PROTECTION'\n",
      "TOBACCO CORPORATIONAL ANALYTICAL PROTECTION PROTECTION\n"
     ]
    }
   ],
   "source": [
    "## example using\n",
    "img = r'E:\\GENAI H2S\\image.png'\n",
    "extracted_text = ETFI(img)\n",
    "\n",
    "print(extracted_text)"
   ]
=======
   "execution_count": 3,
   "id": "47c6e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'GOOGLE_VISION_API.json'\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_vision_anal(img_pth):\n",
    "    try:\n",
    "        with open(img_pth, 'rb') as image_file:\n",
    "            content= image_file.read()\n",
    "        image = vision.Image(content= content)\n",
    "        features= [\n",
    "            {'type_': vision.Feature.Type.DOCUMENT_TEXT_DETECTION},\n",
    "            {'type_': vision.Feature.Type.SAFE_SEARCH_DETECTION},\n",
    "            {'type_': vision.Feature.Type.LANDMARK_DETECTION},\n",
    "            {'type_': vision.Feature.Type.LOGO_DETECTION},\n",
    "            {'type_': vision.Feature.Type.WEB_DETECTION}\n",
    "        ]\n",
    "        response= client.annotate_image({'image': image, 'features': features})\n",
    "        return response, None\n",
    "    except Exception as e:\n",
    "        print(f'an error occured: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71139a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_image_anal(img_pth):\n",
    "    response, error= get_full_vision_anal(img_pth)\n",
    "    if error:\n",
    "        print(f'an error occured {error}')\n",
    "        return {'error': error}\n",
    "    report = {}\n",
    "    # OCR\n",
    "    if response.full_text_anotation:\n",
    "        report['Extracted Text']= response.full_text_anotation.text\n",
    "    # SAFE SEARCH\n",
    "    safe= response.safe_search_anotation\n",
    "    report['Safe Search']= {\n",
    "        'adult': vision.Likelihood(safe.adult).name,\n",
    "        'violence': vision.Likelihood(safe.violence).name,\n",
    "        'spoof': vision.Likelihood(safe.spoof).name\n",
    "    }\n",
    "    # LANDMARKS AND LOGOS\n",
    "    entities= []\n",
    "    for landmark in response.landmark_anotation:\n",
    "        entities.append(f'landmark: {landmark.description}')\n",
    "    for logo in response.logo_anotation:\n",
    "        entities.append(f'Logo: {logo.description}')\n",
    "    if entities:\n",
    "        report['identified_entities']= entities\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fdbbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_img_search(img_pth):\n",
    "    response, error= get_full_vision_anal(img_pth)\n",
    "    if error:\n",
    "        print(f'an error occured: {error}')\n",
    "        return {'error': error}\n",
    "    report= {}\n",
    "    if response.web_detection.pages_with_matching_images:\n",
    "        matches= []\n",
    "        for i in response.web_detection.pages_with_matching_images[:5]:\n",
    "            matches.append({'title': i.page_title, 'url': i.url})\n",
    "        report['reverse_image_matches'] = matches\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d2cd1",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> f76dcb1c84655a30a61595dcf39bf2098e3425c6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
